{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b74ed5ea",
   "metadata": {},
   "source": [
    "# Training a Recommender System with TensorFlow\n",
    "\n",
    "In this notebook I build and train a collaborative filtering recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "80e15d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a3e666",
   "metadata": {},
   "source": [
    "## Step 1: Load and preprocess the dataset\n",
    "\n",
    "We load the preprocessed dataset and make sure that both `userId` and `movieId` are strings.  \n",
    "This is required since TensorFlow's `StringLookup` layer expects string inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "68e1ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(\"ratings_meta_small.csv\")\n",
    "ratings_df[\"userId\"] = ratings_df[\"userId\"].astype(str)\n",
    "ratings_df[\"movieId\"] = ratings_df[\"movieId\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f699f06",
   "metadata": {},
   "source": [
    "## Step 2: Extract unique users and movies\n",
    "\n",
    "We collect all unique users and movies to build vocabularies for the embedding lookups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "332f2534",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users  = ratings_df[\"userId\"].unique()\n",
    "unique_movies = ratings_df[\"movieId\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acadda0b",
   "metadata": {},
   "source": [
    "## Step 3: Build lookup layers\n",
    "\n",
    "We use `StringLookup` layers to map each user- and movieID into integer indices.  \n",
    "This allows us to connect users and movies to embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e9037aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_lookup  = tf.keras.layers.StringLookup(vocabulary=unique_users, mask_token=None)\n",
    "movie_lookup = tf.keras.layers.StringLookup(vocabulary=unique_movies, mask_token=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f959b13",
   "metadata": {},
   "source": [
    "## Step 4: Define embedding size\n",
    "\n",
    "We choose 128 dimensions for both user and movie embeddings.  \n",
    "Larger embeddings capture more information, but also increase model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "7571decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f3d1e6",
   "metadata": {},
   "source": [
    "## Step 5: Build the model\n",
    "\n",
    "We define a collaborative filtering model using embeddings:\n",
    "\n",
    "- User- and movieIDs are mapped to embeddings.\n",
    "- Embeddings are concatenated and passed through Dense layers with ReLU activations.\n",
    "- A final Dense(1) that predicts the rating. No activation is used, so the value can be any real number.\n",
    "\n",
    "This architecture allows the model to learn complex interactions between users and movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b76b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "user_in  = tf.keras.Input(shape=(), dtype=tf.string, name=\"userId\")\n",
    "movie_in = tf.keras.Input(shape=(), dtype=tf.string, name=\"movieId\")\n",
    "\n",
    "# Lookups\n",
    "u_idx = user_lookup(user_in)\n",
    "m_idx = movie_lookup(movie_in)\n",
    "\n",
    "# Embeddings\n",
    "u_emb = tf.keras.layers.Embedding(user_lookup.vocabulary_size(), emb_dim)(u_idx)\n",
    "m_emb = tf.keras.layers.Embedding(movie_lookup.vocabulary_size(), emb_dim)(m_idx)\n",
    "u_emb = tf.keras.layers.Flatten()(u_emb)\n",
    "m_emb = tf.keras.layers.Flatten()(m_emb)\n",
    "\n",
    "# Concatenate user + movie vectors\n",
    "x = tf.keras.layers.Concatenate()([u_emb, m_emb])\n",
    "\n",
    "# Add Dense layers\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "\n",
    "# Output layer\n",
    "pred = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "# Model\n",
    "model = tf.keras.Model(inputs=[user_in, movie_in], outputs=pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff2d068",
   "metadata": {},
   "source": [
    "## Step 6: Compile the model\n",
    "\n",
    "We compile the model with:\n",
    "- **Optimizer**: Adam (adaptive learning rate)\n",
    "- **Loss**: Mean Squared Error (MSE), since we predict numerical ratings\n",
    "- **Metric**: Root Mean Squared Error (RMSE), easier to interpret on rating scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b802a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mse\",\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd72bf0",
   "metadata": {},
   "source": [
    "## Step 7: Train/validation split\n",
    "\n",
    "We split the data into:\n",
    "- **Training set** (90%)\n",
    "- **Validation set** (10%)\n",
    "\n",
    "This allows us to evaluate generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a4981f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(ratings_df, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = {\"userId\": train_df[\"userId\"].values,\n",
    "           \"movieId\": train_df[\"movieId\"].values}\n",
    "y_train = train_df[\"rating\"].values.astype(\"float32\")\n",
    "\n",
    "X_val = {\"userId\": val_df[\"userId\"].values,\n",
    "         \"movieId\": val_df[\"movieId\"].values}\n",
    "y_val = val_df[\"rating\"].values.astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb52f21",
   "metadata": {},
   "source": [
    "## Step 8: Create TensorFlow datasets\n",
    "\n",
    "We convert the NumPy arrays into TensorFlow datasets for efficient training:\n",
    "- `shuffle` randomizes the data each epoch\n",
    "- `batch` groups samples into batches of size 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "88c5bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(y_train)).batch(256)\n",
    "val_ds   = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0a60b4",
   "metadata": {},
   "source": [
    "## Step 9: Train the model\n",
    "\n",
    "We train for up to 10 epochs with early stopping:\n",
    "- **Monitor**: validation RMSE\n",
    "- **Patience**: stop if it does not improve for 2 epochs\n",
    "- **Restore best weights**: rollback to the best-performing model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8f0877fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 1.4403 - rmse: 1.2001 - val_loss: 0.8016 - val_rmse: 0.8953\n",
      "Epoch 2/10\n",
      "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.7179 - rmse: 0.8473 - val_loss: 0.7902 - val_rmse: 0.8889\n",
      "Epoch 3/10\n",
      "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.6179 - rmse: 0.7861 - val_loss: 0.7981 - val_rmse: 0.8934\n",
      "Epoch 4/10\n",
      "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5107 - rmse: 0.7146 - val_loss: 0.8284 - val_rmse: 0.9102\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_rmse\", patience=2, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f727d984",
   "metadata": {},
   "source": [
    "## Step 10: Save the trained model\n",
    "\n",
    "We save the trained recommender system to disk so it can be reused for predictions without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e779a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"recommender_model2.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
